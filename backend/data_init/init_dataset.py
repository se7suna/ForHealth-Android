"""
æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬
ç”¨äºä»æ•°æ®é›†æ–‡ä»¶åˆå§‹åŒ–é£Ÿç‰©æ•°æ®åº“
æ”¯æŒè¦†ç›–å’Œè¿½åŠ æ¨¡å¼
æ³¨æ„ï¼šæ•°æ®é›†æ–‡ä»¶ä¸­çš„æ¯ä¸ªé£Ÿç‰©å¿…é¡»åŒ…å« image_url å­—æ®µ
å›¾ç‰‡å°†ä»å¤–éƒ¨URLä¸‹è½½å¹¶ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿ
"""
import asyncio
import json
import argparse
from datetime import datetime
from pathlib import Path
from motor.motor_asyncio import AsyncIOMotorClient
from typing import List, Dict, Any, Optional
import httpx
import uuid
import io
from PIL import Image
import sys

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥åº”ç”¨æ¨¡å—
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from app.config import settings
    from app.utils.image_storage import get_image_url
    CONFIG_AVAILABLE = True
except ImportError:
    CONFIG_AVAILABLE = False
    print("âš  è­¦å‘Š: æ— æ³•å¯¼å…¥é…ç½®æ¨¡å—ï¼Œå°†ä½¿ç”¨é»˜è®¤è·¯å¾„")


class DatabaseInitializer:
    """æ•°æ®åº“åˆå§‹åŒ–å™¨"""
    
    def __init__(self, dataset_path: str, db_url: str = "mongodb://localhost:27017", db_name: str = "for_health"):
        """
        åˆå§‹åŒ–
        
        Args:
            dataset_path: æ•°æ®é›†æ–‡ä»¶è·¯å¾„
            db_url: MongoDBè¿æ¥URL
            db_name: æ•°æ®åº“åç§°
        """
        self.dataset_path = Path(dataset_path)
        self.db_url = db_url
        self.db_name = db_name
        self.client = None
        self.db = None
    
    async def connect(self):
        """è¿æ¥æ•°æ®åº“"""
        try:
            self.client = AsyncIOMotorClient(self.db_url, serverSelectionTimeoutMS=5000)
            await self.client.admin.command('ping')
            self.db = self.client[self.db_name]
            print(f"âœ“ æˆåŠŸè¿æ¥åˆ°æ•°æ®åº“: {self.db_name}")
            return True
        except Exception as e:
            print(f"âœ— æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False
    
    def load_dataset(self) -> Dict[str, Any]:
        """åŠ è½½æ•°æ®é›†æ–‡ä»¶"""
        try:
            if not self.dataset_path.exists():
                print(f"âœ— æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {self.dataset_path}")
                return None
            
            with open(self.dataset_path, 'r', encoding='utf-8') as f:
                dataset = json.load(f)
            
            print(f"âœ“ æˆåŠŸåŠ è½½æ•°æ®é›†: {self.dataset_path.name}")
            print(f"  ç‰ˆæœ¬: {dataset.get('version', 'æœªçŸ¥')}")
            print(f"  æè¿°: {dataset.get('description', 'æ— ')}")
            print(f"  é£Ÿç‰©æ•°é‡: {len(dataset.get('foods', []))}")
            
            return dataset
        except json.JSONDecodeError as e:
            print(f"âœ— JSONè§£æé”™è¯¯: {e}")
            return None
        except Exception as e:
            print(f"âœ— åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")
            return None
    
    async def clear_collection(self, collection_name: str, delete_images: bool = False):
        """
        æ¸…ç©ºé›†åˆ
        
        Args:
            collection_name: é›†åˆåç§°
            delete_images: æ˜¯å¦åŒæ—¶åˆ é™¤å…³è”çš„å›¾ç‰‡æ–‡ä»¶
        """
        try:
            deleted_image_count = 0
            
            # å¦‚æœéœ€è¦åˆ é™¤å›¾ç‰‡ï¼Œå…ˆè·å–æ‰€æœ‰å›¾ç‰‡URL
            if delete_images and collection_name == "foods":
                try:
                    cursor = self.db[collection_name].find({}, {"image_url": 1})
                    foods = await cursor.to_list(length=None)
                    
                    # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆbackend/ï¼‰
                    backend_dir = Path(__file__).parent.parent
                    
                    for food in foods:
                        image_url = food.get("image_url")
                        if image_url:
                            # åªåˆ é™¤æœ¬åœ°å›¾ç‰‡æ–‡ä»¶ï¼ˆä»¥ http://localhost æˆ–ç›¸å¯¹è·¯å¾„å¼€å¤´çš„ï¼‰
                            if image_url.startswith("http://localhost") or image_url.startswith("https://localhost") or not image_url.startswith(("http://", "https://")):
                                # æå–æ–‡ä»¶è·¯å¾„
                                if image_url.startswith(("http://localhost", "https://localhost")):
                                    # ä»å®Œæ•´URLä¸­æå–ç›¸å¯¹è·¯å¾„
                                    from urllib.parse import urlparse
                                    parsed = urlparse(image_url)
                                    relative_path = parsed.path.lstrip("/")
                                    # å»æ‰ static/ å‰ç¼€
                                    if relative_path.startswith("static/"):
                                        relative_path = relative_path.replace("static/", "", 1)
                                else:
                                    # å‡è®¾å·²ç»æ˜¯ç›¸å¯¹è·¯å¾„
                                    relative_path = image_url
                                
                                # æ„å»ºå®Œæ•´æ–‡ä»¶è·¯å¾„
                                if relative_path.startswith("food_images/"):
                                    file_path = backend_dir / "uploads" / relative_path
                                else:
                                    file_path = backend_dir / "uploads" / "food_images" / relative_path
                                
                                # åˆ é™¤æ–‡ä»¶
                                if file_path.exists() and file_path.is_file():
                                    file_path.unlink()
                                    deleted_image_count += 1
                    
                    if deleted_image_count > 0:
                        print(f"  âœ“ å·²åˆ é™¤ {deleted_image_count} ä¸ªå›¾ç‰‡æ–‡ä»¶")
                except Exception as e:
                    print(f"  âš  åˆ é™¤å›¾ç‰‡æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            
            # æ¸…ç©ºé›†åˆ
            result = await self.db[collection_name].delete_many({})
            print(f"âœ“ å·²æ¸…ç©ºé›†åˆ '{collection_name}': åˆ é™¤ {result.deleted_count} æ¡æ•°æ®")
            return True
        except Exception as e:
            print(f"âœ— æ¸…ç©ºé›†åˆå¤±è´¥: {e}")
            return False
    
    async def get_existing_foods(self) -> List[str]:
        """è·å–å·²å­˜åœ¨çš„é£Ÿç‰©åç§°åˆ—è¡¨"""
        try:
            cursor = self.db.foods.find({}, {"name": 1})
            foods = await cursor.to_list(length=None)
            return [food.get("name") for food in foods]
        except Exception as e:
            print(f"âœ— è·å–ç°æœ‰é£Ÿç‰©åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    async def download_and_save_image(self, image_url: str, food_name: str) -> Optional[str]:
        """
        ä»å¤–éƒ¨URLä¸‹è½½å›¾ç‰‡å¹¶ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿï¼ˆä¸image_storage.pyçš„å­˜å‚¨æ–¹å¼ä¸€è‡´ï¼‰
        
        Args:
            image_url: å¤–éƒ¨å›¾ç‰‡URL
            food_name: é£Ÿç‰©åç§°ï¼ˆç”¨äºç”Ÿæˆæ–‡ä»¶åï¼‰
            
        Returns:
            æœ¬åœ°å›¾ç‰‡è®¿é—®URLï¼Œå¦‚æœä¸‹è½½å¤±è´¥åˆ™è¿”å›None
        """
        if not image_url or not image_url.startswith(("http://", "https://")):
            return None
        
        try:
            # ä¸‹è½½å›¾ç‰‡
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(image_url)
                response.raise_for_status()
                content = response.content
            
            # æ£€æŸ¥æ–‡ä»¶å¤§å°ï¼ˆ10MBé™åˆ¶ï¼‰
            MAX_FILE_SIZE = 10 * 1024 * 1024
            if len(content) > MAX_FILE_SIZE:
                print(f"    âš  å›¾ç‰‡è¿‡å¤§ï¼Œè·³è¿‡: {image_url}")
                return None
            
            # éªŒè¯å›¾ç‰‡æ ¼å¼
            try:
                image = Image.open(io.BytesIO(content))
                image.verify()
            except Exception as e:
                print(f"    âš  æ— æ•ˆçš„å›¾ç‰‡æ ¼å¼ï¼Œè·³è¿‡: {str(e)}")
                return None
            
            # é‡æ–°æ‰“å¼€å›¾ç‰‡ï¼ˆverifyåéœ€è¦é‡æ–°æ‰“å¼€ï¼‰
            image = Image.open(io.BytesIO(content))
            
            # å‹ç¼©å›¾ç‰‡ï¼ˆå¦‚æœå¤ªå¤§ï¼‰
            max_size = (2000, 2000)
            if image.size[0] > max_size[0] or image.size[1] > max_size[1]:
                image.thumbnail(max_size, Image.Resampling.LANCZOS)
            
            # ç¡®å®šæ–‡ä»¶æ‰©å±•å
            content_type = response.headers.get("content-type", "")
            if "jpeg" in content_type or "jpg" in content_type:
                file_ext = ".jpg"
            elif "png" in content_type:
                file_ext = ".png"
            elif "webp" in content_type:
                file_ext = ".webp"
            elif "gif" in content_type:
                file_ext = ".gif"
            else:
                # å°è¯•ä»URLä¸­è·å–æ‰©å±•å
                from urllib.parse import urlparse
                parsed = urlparse(image_url)
                path_ext = Path(parsed.path).suffix.lower()
                if path_ext in [".jpg", ".jpeg", ".png", ".webp", ".gif"]:
                    file_ext = path_ext
                else:
                    file_ext = ".jpg"  # é»˜è®¤ä½¿ç”¨jpg
            
            # ç”Ÿæˆæ–‡ä»¶åï¼ˆä½¿ç”¨é£Ÿç‰©åç§°çš„å“ˆå¸Œå’ŒUUIDï¼‰
            food_name_hash = str(hash(food_name))[:8]
            filename = f"{food_name_hash}_{uuid.uuid4().hex[:8]}{file_ext}"
            
            # è·å–å­˜å‚¨è·¯å¾„ï¼ˆå§‹ç»ˆåŸºäºé¡¹ç›®æ ¹ç›®å½• backend/ï¼‰
            # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„çˆ¶ç›®å½•ï¼ˆbackend/ï¼‰
            backend_dir = Path(__file__).parent.parent  # backend/data_init -> backend/
            
            # ç¡®ä¿è·¯å¾„åŸºäº backend/ ç›®å½•ï¼Œé¿å…åœ¨æ ¹ç›®å½•åˆ›å»ºæ–‡ä»¶å¤¹
            if CONFIG_AVAILABLE:
                # ä½¿ç”¨é…ç½®ä¸­çš„è·¯å¾„ï¼Œä½†ç¡®ä¿åŸºäºé¡¹ç›®æ ¹ç›®å½•
                base_path_str = settings.IMAGE_STORAGE_PATH
                if Path(base_path_str).is_absolute():
                    base_path = Path(base_path_str)
                else:
                    # ç¡®ä¿è·¯å¾„åŸºäº backend/ ç›®å½•
                    base_path = backend_dir / base_path_str
                storage_path = base_path / "food_images"
            else:
                # å›é€€åˆ°é»˜è®¤è·¯å¾„ï¼ˆç¡®ä¿åŸºäº backend/ ç›®å½•ï¼‰
                storage_path = backend_dir / "uploads" / "food_images"
            
            # ç¡®ä¿ storage_path æ˜¯ backend/ çš„å­ç›®å½•
            try:
                storage_path.relative_to(backend_dir)
            except ValueError:
                # å¦‚æœè·¯å¾„ä¸åœ¨ backend/ ç›®å½•ä¸‹ï¼Œå¼ºåˆ¶ä½¿ç”¨ backend/uploads/food_images
                storage_path = backend_dir / "uploads" / "food_images"
            
            # åªåœ¨éœ€è¦æ—¶åˆ›å»ºæ–‡ä»¶å¤¹ï¼ˆç¡®ä¿è·¯å¾„æ­£ç¡®ï¼‰
            if not storage_path.exists():
                storage_path.mkdir(parents=True, exist_ok=True)
            
            file_path = storage_path / filename
            
            # ä¿å­˜å›¾ç‰‡
            image.save(file_path, quality=85, optimize=True)
            
            # ç”Ÿæˆæœ¬åœ°è®¿é—®URL
            relative_path = f"food_images/{filename}"
            if CONFIG_AVAILABLE:
                local_url = get_image_url(relative_path)
            else:
                # å›é€€åˆ°é»˜è®¤URLæ ¼å¼
                local_url = f"http://localhost:8000/static/{relative_path}"
            
            return local_url
            
        except httpx.HTTPError as e:
            print(f"    âš  ä¸‹è½½å›¾ç‰‡å¤±è´¥: {str(e)}")
            return None
        except Exception as e:
            print(f"    âš  ä¿å­˜å›¾ç‰‡å¤±è´¥: {str(e)}")
            return None
    
    async def insert_foods(self, foods: List[Dict[str, Any]], skip_existing: bool = False):
        """
        æ’å…¥é£Ÿç‰©æ•°æ®
        
        Args:
            foods: é£Ÿç‰©æ•°æ®åˆ—è¡¨ï¼ˆæ¯ä¸ªé£Ÿç‰©å¿…é¡»åŒ…å« image_url å­—æ®µï¼‰
            skip_existing: æ˜¯å¦è·³è¿‡å·²å­˜åœ¨çš„é£Ÿç‰©
        """
        if not foods:
            print("âœ— æ²¡æœ‰è¦æ’å…¥çš„é£Ÿç‰©æ•°æ®")
            return
        
        # æ·»åŠ æ—¶é—´æˆ³
        now = datetime.utcnow()
        for food in foods:
            food['created_at'] = now
            food['updated_at'] = now
        
        success_count = 0
        skip_count = 0
        error_count = 0
        missing_image_count = 0
        
        if skip_existing:
            # è·å–å·²å­˜åœ¨çš„é£Ÿç‰©åç§°
            existing_names = set(await self.get_existing_foods())
            print(f"  æ•°æ®åº“ä¸­å·²æœ‰ {len(existing_names)} ä¸ªé£Ÿç‰©")
        
        for food in foods:
            try:
                food_name = food.get('name', 'æœªå‘½å')
                original_image_url = food.get('image_url')
                
                # æ£€æŸ¥æ˜¯å¦æœ‰ image_url
                if not original_image_url:
                    missing_image_count += 1
                    print(f"  âš  è­¦å‘Š: '{food_name}' ç¼ºå°‘ image_url å­—æ®µ")
                else:
                    # å¦‚æœæ˜¯å¤–éƒ¨URLï¼Œä¸‹è½½å¹¶ä¿å­˜åˆ°æœ¬åœ°
                    if original_image_url.startswith(("http://", "https://")):
                        print(f"  ğŸ“¥ æ­£åœ¨ä¸‹è½½å›¾ç‰‡: {food_name}...", end='', flush=True)
                        local_image_url = await self.download_and_save_image(original_image_url, food_name)
                        if local_image_url:
                            food['image_url'] = local_image_url
                            print(f" âœ“")
                        else:
                            # ä¸‹è½½å¤±è´¥ï¼Œä¿ç•™åŸå§‹URL
                            print(f" âœ— (ä¿ç•™åŸå§‹URL)")
                    # å¦‚æœå·²ç»æ˜¯æœ¬åœ°URLï¼Œç›´æ¥ä½¿ç”¨
                    else:
                        pass  # ä¿æŒåŸæ ·
                
                # å¦‚æœéœ€è¦è·³è¿‡å·²å­˜åœ¨çš„é£Ÿç‰©
                if skip_existing and food_name in existing_names:
                    skip_count += 1
                    print(f"  âŠ˜ è·³è¿‡å·²å­˜åœ¨çš„é£Ÿç‰©: {food_name}")
                    continue
                
                # æ’å…¥é£Ÿç‰©
                await self.db.foods.insert_one(food)
                success_count += 1
                image_status = "ğŸ“·" if food.get('image_url') else "âš "
                print(f"  âœ“ å·²æ’å…¥: {food_name} ({food.get('category', 'æœªåˆ†ç±»')}) {image_status}")
                
            except Exception as e:
                error_count += 1
                print(f"  âœ— æ’å…¥å¤±è´¥: {food.get('name', 'æœªçŸ¥')} - {e}")
        
        print(f"\næ’å…¥ç»“æœ:")
        print(f"  æˆåŠŸ: {success_count} ä¸ª")
        if skip_count > 0:
            print(f"  è·³è¿‡: {skip_count} ä¸ª")
        if error_count > 0:
            print(f"  å¤±è´¥: {error_count} ä¸ª")
        if missing_image_count > 0:
            print(f"  âš  ç¼ºå°‘ image_url: {missing_image_count} ä¸ª")
    
    async def init_database(self, overwrite: bool = False, skip_existing: bool = False):
        """
        åˆå§‹åŒ–æ•°æ®åº“
        
        Args:
            overwrite: æ˜¯å¦è¦†ç›–ç°æœ‰æ•°æ®ï¼ˆæ¸…ç©ºåé‡æ–°æ’å…¥ï¼‰
            skip_existing: æ˜¯å¦è·³è¿‡å·²å­˜åœ¨çš„é£Ÿç‰©ï¼ˆä»…åœ¨ä¸è¦†ç›–æ—¶æœ‰æ•ˆï¼‰
        """
        print("=" * 80)
        print("å¼€å§‹åˆå§‹åŒ–æ•°æ®åº“")
        print("=" * 80)
        print(f"æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"æ¨¡å¼: {'è¦†ç›–æ¨¡å¼' if overwrite else ('è·³è¿‡å·²å­˜åœ¨' if skip_existing else 'è¿½åŠ æ¨¡å¼')}")
        print("=" * 80)
        
        # 1. è¿æ¥æ•°æ®åº“
        if not await self.connect():
            return False
        
        # 2. åŠ è½½æ•°æ®é›†
        dataset = self.load_dataset()
        if not dataset:
            return False
        
        foods = dataset.get('foods', [])
        if not foods:
            print("âœ— æ•°æ®é›†ä¸­æ²¡æœ‰é£Ÿç‰©æ•°æ®")
            return False
        
        # 3. å¤„ç†è¦†ç›–æ¨¡å¼
        if overwrite:
            print("\nâš  è­¦å‘Š: è¦†ç›–æ¨¡å¼ - å°†åˆ é™¤æ‰€æœ‰ç°æœ‰é£Ÿç‰©æ•°æ®åŠå…¶å…³è”çš„å›¾ç‰‡æ–‡ä»¶")
            response = input("ç¡®è®¤ç»§ç»­? (yes/no): ").strip().lower()
            if response != 'yes':
                print("âœ— æ“ä½œå·²å–æ¶ˆ")
                return False
            
            if not await self.clear_collection("foods", delete_images=True):
                return False
        
        # 4. æ’å…¥é£Ÿç‰©æ•°æ®
        print(f"\nå¼€å§‹æ’å…¥ {len(foods)} ä¸ªé£Ÿç‰©...")
        print("-" * 80)
        
        await self.insert_foods(
            foods, 
            skip_existing=skip_existing and not overwrite
        )
        
        # 5. ç»Ÿè®¡ä¿¡æ¯
        print("\n" + "=" * 80)
        print("æ•°æ®åº“ç»Ÿè®¡:")
        print("=" * 80)
        
        total_count = await self.db.foods.count_documents({})
        print(f"é£Ÿç‰©æ€»æ•°: {total_count}")
        
        # æŒ‰ç±»åˆ«ç»Ÿè®¡
        pipeline = [
            {"$group": {"_id": "$category", "count": {"$sum": 1}}},
            {"$sort": {"count": -1}}
        ]
        categories = await self.db.foods.aggregate(pipeline).to_list(length=None)
        
        print("\næŒ‰ç±»åˆ«ç»Ÿè®¡:")
        for cat in categories:
            cat_name = cat['_id'] if cat['_id'] else 'æœªåˆ†ç±»'
            print(f"  {cat_name}: {cat['count']} ä¸ª")
        
        print("\n" + "=" * 80)
        print("âœ“ æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ!")
        print("=" * 80)
        
        return True
    
    async def close(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.client:
            self.client.close()
            print("\nâœ“ æ•°æ®åº“è¿æ¥å·²å…³é—­")


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='åˆå§‹åŒ–é£Ÿç‰©æ•°æ®åº“',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # è¿½åŠ æ¨¡å¼ï¼ˆä¿ç•™ç°æœ‰æ•°æ®ï¼Œæ·»åŠ æ–°æ•°æ®ï¼‰
  python init_database.py
  
  # è¦†ç›–æ¨¡å¼ï¼ˆåˆ é™¤æ‰€æœ‰ç°æœ‰æ•°æ®ï¼Œé‡æ–°åˆå§‹åŒ–ï¼‰
  python init_database.py --overwrite
  
  # è·³è¿‡å·²å­˜åœ¨çš„é£Ÿç‰©ï¼ˆä»…æ·»åŠ æ–°é£Ÿç‰©ï¼‰
  python init_database.py --skip-existing
  
  # ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®é›†æ–‡ä»¶
  python init_database.py --dataset my_foods.json
        """
    )
    
    parser.add_argument(
        '--dataset',
        type=str,
        default='initial_foods_dataset.json'
    )
    
    parser.add_argument(
        '--overwrite',
        action='store_true',
        default=True,
        help='è¦†ç›–æ¨¡å¼ï¼šåˆ é™¤æ‰€æœ‰ç°æœ‰æ•°æ®åé‡æ–°åˆå§‹åŒ–ï¼ˆé»˜è®¤å¯ç”¨ï¼‰'
    )
    
    parser.add_argument(
        '--skip-existing',
        action='store_true',
        help='è·³è¿‡å·²å­˜åœ¨çš„é£Ÿç‰©ï¼ˆä»…åœ¨éè¦†ç›–æ¨¡å¼ä¸‹æœ‰æ•ˆï¼‰'
    )
    
    parser.add_argument(
        '--db-url',
        type=str,
        default='mongodb://localhost:27017',
        help='MongoDBè¿æ¥URL (é»˜è®¤: mongodb://localhost:27017)'
    )
    
    parser.add_argument(
        '--db-name',
        type=str,
        default='for_health',
        help='æ•°æ®åº“åç§° (é»˜è®¤: for_health)'
    )
    
    args = parser.parse_args()
    
    # åˆ›å»ºåˆå§‹åŒ–å™¨
    initializer = DatabaseInitializer(
        dataset_path=args.dataset,
        db_url=args.db_url,
        db_name=args.db_name
    )
    
    try:
        # æ‰§è¡Œåˆå§‹åŒ–
        success = await initializer.init_database(
            overwrite=args.overwrite,
            skip_existing=args.skip_existing
        )
        
        if success:
            print("\nğŸ‰ åˆå§‹åŒ–æˆåŠŸï¼")
        else:
            print("\nâŒ åˆå§‹åŒ–å¤±è´¥ï¼")
            
    except KeyboardInterrupt:
        print("\n\nâš  æ“ä½œè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        await initializer.close()


if __name__ == '__main__':
    asyncio.run(main())

